{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image  # to read images\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import Compose, LoadImage, Resize, ToTensor, Activations, AsDiscrete\n",
    "from monai.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set flag to load truncated images\n",
    "Image.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Path to the ground truth JSON file\n",
    "gt_json_file = \"./scripts/instances_val.json\"\n",
    "\n",
    "# Loop over four sea state classes\n",
    "for ii in range(4):\n",
    "    # Define the directory containing sea state images\n",
    "    images_directory = f\"./sea_state_classified/{ii+1}\"\n",
    "\n",
    "    # Iterate through files in the images directory\n",
    "    for filename in os.listdir(images_directory):\n",
    "        # Extract relevant information from the filename\n",
    "        ori_filename = filename.split(\"_\")[2]\n",
    "        seed = ori_filename[0]\n",
    "        im_id = ori_filename.split('.')[0]\n",
    "        bbox = []\n",
    "\n",
    "        # Open the ground truth JSON file\n",
    "        with open(gt_json_file, encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            count = 0\n",
    "\n",
    "            # Iterate through annotations in the JSON data\n",
    "            for annotation in data[\"annotations\"]:\n",
    "                if int(annotation[\"image_id\"]) == int(im_id) and int(annotation[\"category_id\"]) == 2:\n",
    "                    bbox = annotation[\"bbox\"]\n",
    "                    category = annotation[\"category_id\"]\n",
    "                    bbox = [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]\n",
    "\n",
    "                    try:\n",
    "                        # Open the image, crop it based on the bounding box, and save the cropped image\n",
    "                        img = Image.open(f\"{images_directory}/{filename}\")\n",
    "                        img = img.crop(bbox)\n",
    "                        img.save(\n",
    "                            f\"./crops/{ii+1}/{filename.split('.')[0]}__{bbox[0]}_{bbox[1]}_{bbox[2]}_{bbox[3]}.jpg\"\n",
    "                        )\n",
    "\n",
    "                    except IOError:\n",
    "                        # Handle IOError if the image cannot be opened or saved\n",
    "                        pass\n",
    "\n",
    "                    count += 1  # Increment count for each matched annotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms and Dataloader \n",
    "class SumDimension:\n",
    "    def __init__(self, dim=1):\n",
    "        self.dim = dim\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return inputs.sum(self.dim)\n",
    "\n",
    "class MyResize:\n",
    "    def __init__(self, size=(120, 120)):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        image = cv2.resize(inputs, dsize=(self.size[1], self.size[0]), interpolation=cv2.INTER_CUBIC)\n",
    "        return image[30:90, 30:90]\n",
    "\n",
    "class Astype:\n",
    "    def __init__(self, type='uint8'):\n",
    "        self.type = type\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return inputs.astype(self.type)\n",
    "\n",
    "class AddChannel:\n",
    "    def __call__(self, img):\n",
    "        return img[None]\n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadImage(image_only=True),\n",
    "    Resize((-1, 1)),\n",
    "    Astype(),\n",
    "    SumDimension(2),\n",
    "    Astype(),\n",
    "    MyResize(),\n",
    "    AddChannel(),\n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "to_onehot = AsDiscrete(to_onehot=6, n_classes=6)\n",
    "\n",
    "class MedNISTDataset(Dataset):\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "# Load model\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = DenseNet121(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('./models/boat_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Run test\n",
    "for ii in range(4):\n",
    "    main_dir = f\"./crops/{ii+1}\"\n",
    "    for filename in os.listdir(main_dir):\n",
    "        shutil.move(f\"{main_dir}/{filename}\", f\"./temp_boat/1/{filename}\")\n",
    "        y_true, y_pred = [], []\n",
    "\n",
    "        editted_test_dir = './temp_boat'\n",
    "\n",
    "        t_class_names = sorted(os.listdir(editted_test_dir))\n",
    "        t_image_files = [[os.path.join(editted_test_dir, t_class_name, x) \n",
    "                    for x in os.listdir(os.path.join(editted_test_dir, t_class_name))] \n",
    "                    for t_class_name in t_class_names]\n",
    "\n",
    "        t_image_file_list = [x for sublist in t_image_files for x in sublist]\n",
    "        t_image_label_list = [i for i, sublist in enumerate(t_image_files) for _ in sublist]\n",
    "\n",
    "        testX, testY = np.array(t_image_file_list), np.array(t_image_label_list)\n",
    "\n",
    "        editted_test_ds = MedNISTDataset(testX, testY, val_transforms)\n",
    "        editted_test_loader = DataLoader(editted_test_ds, batch_size=32, num_workers=2)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for test_data in editted_test_loader:\n",
    "                test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
    "                pred = model(test_images.float()).argmax(dim=1)\n",
    "                y_pred.extend(pred.cpu().numpy())\n",
    "                shutil.move(f\"./temp_boat/1/{filename}\", f\"./crops_checked/{ii+1}/{pred[0].item()}/{filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code snippet iterates over four sea state classes (1 to 4).\n",
    "for ii in range(4):\n",
    "    # Define the directory path for the sea state images.\n",
    "    image_directory = f\"./sea_state_classified/{ii+1}\"\n",
    "\n",
    "    # Define the directory path for checked crops corresponding to each sea state class.\n",
    "    crop_directory = f\"./crops_checked/{ii+1}/1\"\n",
    "\n",
    "    # Create an empty list to store unique image names from the checked crops directory.\n",
    "    image_list = []\n",
    "\n",
    "    # Iterate through files in the checked crops directory.\n",
    "    for filename in os.listdir(crop_directory):\n",
    "        # Extract the base image name (excluding any additional information).\n",
    "        base_image_name = filename.split('__')[0]\n",
    "\n",
    "        # Check if the base image name is not already in the list.\n",
    "        if base_image_name not in image_list:\n",
    "            # Add the base image name to the list.\n",
    "            image_list.append(base_image_name)\n",
    "\n",
    "    # Iterate through files in the sea state images directory.\n",
    "    for filename in os.listdir(image_directory):\n",
    "        # Extract the base image name (excluding file extension).\n",
    "        base_image_name = filename.split('.')[0]\n",
    "\n",
    "        # Check if the base image name is not in the list obtained from checked crops.\n",
    "        if base_image_name not in image_list:\n",
    "            # Remove the image file from the sea state images directory.\n",
    "            os.remove(f\"{image_directory}/{filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ii in range(4):\n",
    "#     # Define the directory path for the sea state images.\n",
    "#     image_directory = f\"./sea_state_classified/{ii+1}\"\n",
    "\n",
    "#     # Define the directory path for checked crops corresponding to each sea state class.\n",
    "#     crop_directory = f\"./crops_checked/{ii+1}/1\"\n",
    "#     for filename in os.listdir(crop_directory):\n",
    "#          os.remove(f\"{crop_directory}/{filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

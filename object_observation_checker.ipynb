{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # to read images\n",
    "import os\n",
    "import json\n",
    "\n",
    "Image.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "gt_jf=\"./scripts/instances_val.json\"\n",
    "for ii in range (4):\n",
    "    # images_directory=f\"./new_editted_classified_resized/{sub_dir}/{batch}/{ii+1}/\"\n",
    "    images_directory=f\"./sea_state_classified/{ii+1}\"\n",
    "    for filename in os.listdir(images_directory):\n",
    "        ori_filename = filename.split(\"_\")[2]\n",
    "        seed = ori_filename[0]\n",
    "        im_id = ori_filename.split('.')[0]\n",
    "        bbox=[]\n",
    "        with open(gt_jf, encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            count = 0\n",
    "            for annotation in data[\"annotations\"]:\n",
    "                if int(annotation[\"image_id\"]) == int(im_id) and int(annotation[\"category_id\"]) ==2:\n",
    "                    bbox = annotation[\"bbox\"]\n",
    "                    category = annotation[\"category_id\"]\n",
    "                    bbox = [bbox[0], bbox[1] ,bbox[0]+bbox[2], bbox[1]+bbox[3]]\n",
    "                    try:\n",
    "                        img=Image.open(f\"{images_directory}/{filename}\")\n",
    "                        img=img.crop(bbox)\n",
    "                        img.save(f\"./crops/{ii+1}/{filename}__{bbox[0]}_{bbox[1]}_{bbox[2]}_{bbox[3]}.jpg\")\n",
    "                        \n",
    "                    except IOError:\n",
    "                        \n",
    "                        pass\n",
    "                    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import *\n",
    "from monai.data import Dataset, DataLoader\n",
    "\n",
    "##Define MONAI transforms, Dataset and Dataloader to pre-process data\n",
    "class SumDimension(Transform):\n",
    "    def __init__(self, dim=1):\n",
    "        self.dim = dim\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return inputs.sum(self.dim)\n",
    "class MyResize(Transform):\n",
    "    def __init__(self, size=(120,120)):\n",
    "        self.size = size\n",
    "    def __call__(self, inputs):\n",
    "        image=cv2.resize(inputs,dsize=(self.size[1],self.size[0]),interpolation=cv2.INTER_CUBIC)\n",
    "        image2=image[30:90,30:90]\n",
    "        return image2\n",
    "class Astype(Transform):\n",
    "    def __init__(self, type='uint8'):\n",
    "        self.type = type\n",
    "    def __call__(self, inputs):\n",
    "        return inputs.astype(self.type)\n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadImage(image_only=True),\n",
    "    Resize((-1,1)),\n",
    "    Astype(),\n",
    "    SumDimension(2),\n",
    "    Astype(),\n",
    "    MyResize(),\n",
    "    AddChannel(),    \n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "act = Activations(softmax=True)\n",
    "to_onehot = AsDiscrete(to_onehot=6, n_classes=6)\n",
    "##to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.\n",
    "class MedNISTDataset(Dataset):\n",
    "\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\")   #\"cuda:0\"\n",
    "model = DenseNet121(\n",
    "    spatial_dims=2,            \n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('./models/boat_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "for ii in range(4):\n",
    "    main_dir = f\"./crops/{ii+1}\"\n",
    "    for filename in os.listdir(main_dir):\n",
    "        # if (int(filename.split('_')[0])<100):\n",
    "        shutil.move(f\"{main_dir}/{filename}\", f\"./temp_boat/1/{filename}\")\n",
    "        y_true = list()\n",
    "        y_pred = list()\n",
    "\n",
    "        editted_test_dir='./temp_boat'\n",
    "        #test\n",
    "        t_class_names0 = os.listdir(editted_test_dir)\n",
    "        t_class_names = sorted(t_class_names0)\n",
    "\n",
    "        t_num_class = len(t_class_names)\n",
    "        t_image_files = [[os.path.join(editted_test_dir, t_class_name, x) \n",
    "                    for x in os.listdir(os.path.join(editted_test_dir, t_class_name))] \n",
    "                    for t_class_name in t_class_names]\n",
    "\n",
    "        t_image_file_list = []\n",
    "        t_image_label_list = []\n",
    "        for i, class_name in enumerate(t_class_names):\n",
    "            t_image_file_list.extend(t_image_files[i])\n",
    "            t_image_label_list.extend([i] * len(t_image_files[i]))\n",
    "\n",
    "        testX=np.array(t_image_file_list)\n",
    "        testY=np.array(t_image_label_list)\n",
    "\n",
    "        editted_test_ds = MedNISTDataset(testX, testY, val_transforms)\n",
    "        editted_test_loader = DataLoader(editted_test_ds, batch_size=32, num_workers=2)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for test_data in editted_test_loader:\n",
    "                test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
    "                pred = model(test_images.float()).argmax(dim=1)\n",
    "                for i in range(len(pred)):\n",
    "                    y_pred.append(pred[i].item())\n",
    "                    shutil.move(f\"./temp_boat/1/{filename}\", f\"./crops_checked/{ii+1}/{pred[0].item()}/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(4):\n",
    "    image_directory = f\"./sea_state_classified/{ii+1}\"\n",
    "    crop_directory = f\"./crops_checked/{ii+1}/1\"\n",
    "    image_list = []\n",
    "    for filename in os.listdir(crop_directory):\n",
    "        if filename.split('__')[0] not in image_list:\n",
    "            image_list.append(filename.split('__')[0])\n",
    "    for filename in os.listdir(image_directory):\n",
    "        if filename.split('.')[0] not in image_list:\n",
    "            os.remove(f\"{image_directory}/{filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

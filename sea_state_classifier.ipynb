{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\marti\\OneDrive - Queensland University of Technology\\Research\\Seadrone\\SafeSea\\sea_state_classifier.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marti/OneDrive%20-%20Queensland%20University%20of%20Technology/Research/Seadrone/SafeSea/sea_state_classifier.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marti/OneDrive%20-%20Queensland%20University%20of%20Technology/Research/Seadrone/SafeSea/sea_state_classifier.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/marti/OneDrive%20-%20Queensland%20University%20of%20Technology/Research/Seadrone/SafeSea/sea_state_classifier.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marti/OneDrive%20-%20Queensland%20University%20of%20Technology/Research/Seadrone/SafeSea/sea_state_classifier.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmonai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marti/OneDrive%20-%20Queensland%20University%20of%20Technology/Research/Seadrone/SafeSea/sea_state_classifier.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmonai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset, DataLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from monai.transforms import *\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.networks.nets import DenseNet121\n",
    "import shutil\n",
    "import os\n",
    "from PIL import Image\n",
    "# assign directory\n",
    "\n",
    "##Define MONAI transforms, Dataset and Dataloader to pre-process data\n",
    "class SumDimension(Transform):\n",
    "    def __init__(self, dim=1):\n",
    "        self.dim = dim\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return inputs.sum(self.dim)\n",
    "class MyResize(Transform):\n",
    "    def __init__(self, size=(120,120)):\n",
    "        self.size = size\n",
    "    def __call__(self, inputs):\n",
    "        image=cv2.resize(inputs,dsize=(self.size[1],self.size[0]),interpolation=cv2.INTER_CUBIC)\n",
    "        image2=image[30:90,30:90]\n",
    "        return image2\n",
    "class Astype(Transform):\n",
    "    def __init__(self, type='uint8'):\n",
    "        self.type = type\n",
    "    def __call__(self, inputs):\n",
    "        return inputs.astype(self.type)\n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadImage(image_only=True),\n",
    "    Resize((-1,1)),\n",
    "    Astype(),\n",
    "    SumDimension(2),\n",
    "    Astype(),\n",
    "    MyResize(),\n",
    "    AddChannel(),    \n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "class MedNISTDataset(Dataset):\n",
    "\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "editted_test_dir='./temp'\n",
    "\n",
    "device = torch.device(\"cuda:0\")   #\"cuda:0\"\n",
    "model = DenseNet121(\n",
    "    spatial_dims=2,            \n",
    "    in_channels=1,\n",
    "    out_channels=4,\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('./models/sea_state_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "#test\n",
    "t_class_names0 = os.listdir(editted_test_dir)\n",
    "t_class_names = sorted(t_class_names0)\n",
    "t_num_class = len(t_class_names)\n",
    "\n",
    "#image directory\n",
    "image_directory = './outputs'\n",
    "\n",
    "for filename in os.listdir(image_directory):\n",
    "    f = os.path.join(image_directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        shutil.move(f, f\"temp/1/{filename}\")\n",
    "        t_image_files = [[os.path.join(editted_test_dir, t_class_name, x) \n",
    "                    for x in os.listdir(os.path.join(editted_test_dir, t_class_name))] \n",
    "                    for t_class_name in t_class_names]\n",
    "\n",
    "        t_image_file_list = []\n",
    "        t_image_label_list = []\n",
    "        for i, class_name in enumerate(t_class_names):\n",
    "            t_image_file_list.extend(t_image_files[i])\n",
    "            t_image_label_list.extend([i] * len(t_image_files[i]))\n",
    "        ['1', '2', '3', '4']\n",
    "\n",
    "        testX=np.array(t_image_file_list)\n",
    "        testY=np.array(t_image_label_list)\n",
    "\n",
    "        editted_test_ds = MedNISTDataset(testX, testY, val_transforms)\n",
    "        editted_test_loader = DataLoader(editted_test_ds, batch_size=32, num_workers=2)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for test_data in editted_test_loader:\n",
    "                test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
    "                pred = model(test_images.float()).argmax(dim=1)\n",
    "                for i in range(len(pred)):\n",
    "                    for filename in os.listdir(f\"temp/{test_labels[i].item()+1}\"):\n",
    "                        original_image_path = f\"../inputs/val_images/{filename.split('_')[2]}\"\n",
    "                        original_image = Image.open(original_image_path)\n",
    "                        original_size = original_image.size\n",
    "                        image = Image.open(f).resize(original_size)\n",
    "                        image.save( f\"sea_state_classified/{pred[i].item()+1}/{filename}\")\n",
    "                        os.remove(f\"temp/{test_labels[i].item()+1}/{filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
